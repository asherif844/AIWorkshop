{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summarizing Text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, you will get to experiment with performing extraction based summarization of text. This technique of summarization attempts to identify key sentences in a provided text and returns a summary that is the result of returning just those key sentences. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process we will follow to summarize text is a subset of the text analytics pipeline that includes these steps:  \n",
    "- Normalize the text: in this case, simply to clean the text of line break characters. This followed by some simple sentence tokenization, which breaks the paragraph into sentences and removes any extra trailing spaces. Finally the cleaned up text is returned as string.\n",
    "- Apply the analytic method: in this case, we use the summarize method provided by the gensim library to generate the summarized result."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1 - Import modules"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we need to import the modules used by our logic. Note that you will have to have installed gensim using \"pip install gensim\" prior to being able to run this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-b3e0684efaf6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0municodedata\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msummarization\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "import unicodedata\n",
    "import numpy as np\n",
    "from gensim.summarization import summarize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NOTE: You can safely ignore the warning in the above cell that indicates a warning \"aliasing chunksize to chunksize_serial\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2 - Normalize text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we define a method that will remove line break characters, tokenize the paragraph of text into an array of string sentences and then strip any extra spaces surrounding a sentence. This is an example of a simple, but typical, text normalization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_and_parse_document(document):\n",
    "    document = re.sub('\\n', ' ', document)\n",
    "    document = document.strip()\n",
    "    sentences = nltk.sent_tokenize(document)\n",
    "    sentences = [sentence.strip() for sentence in sentences]\n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3 - Summarize text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following, we define a method that uses the summarize method from the gensim module. We take the pre-processed output from our clean_and_parse_document routine and convert the array of string sentences to a single text item by concatenating the sentences. When performing text analytics, some analytic methods might require tokenized input and others may require string input, so this is a common process. In this, the summarize method requires a text string as input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def summarize_text(text, summary_ratio=None, word_count=30):\n",
    "    sentences = clean_and_parse_document(text)\n",
    "    cleaned_text = ' '.join(sentences)\n",
    "    summary = summarize(cleaned_text, split=True, ratio=summary_ratio, word_count=word_count)\n",
    "    return summary "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 4 - Try it out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Author an example string that represents a rather long claim description that Contoso Ltd. might encounter. An example is provided for you, but feel free to provide your own. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "example_document = \"\"\"\n",
    "I was driving down El Camino and stopped at a red light.\n",
    "It was about 3pm in the afternoon.  \n",
    "The sun was bright and shining just behind the stoplight.\n",
    "This made it hard to see the lights.\n",
    "There was a car on my left in the left turn lane.\n",
    "A few moments later another car, a black sedan pulled up behind me. \n",
    "When the left turn light changed green, the black sedan hit me thinking \n",
    "that the light had changed for us, but I had not moved because the light \n",
    "was still red.\n",
    "After hitting my car, the black sedan backed up and then sped past me.\n",
    "I did manage to catch its license plate. \n",
    "The license plate of the black sedan was ABC123. \n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, invoke your summarize_text function against the example document and observe the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "summarize_text(example_document)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the summary is returned as an array of string. If multiple sentences were returned, there would be multiple array entries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 5 - Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. The summarize text function above defaults to providing a summary that is about 30 words long. What happens if you attempt to summarize the text to 60 words?\n",
    "2. What happens when you submit a text to summarize that is shorter than the summary target length?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
